<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="徐涛的个人主页">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="徐涛的个人主页">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="徐涛的个人主页">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/">





  <title>徐涛的个人主页</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">徐涛的个人主页</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/09/flink-action-until-jobGraph/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="徐涛">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="徐涛的个人主页">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/09/flink-action-until-jobGraph/" itemprop="url">Flink生成JobGraph的过程</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-09T22:55:28+08:00">
                2019-03-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Flink源码阅读笔记"><a href="#Flink源码阅读笔记" class="headerlink" title="Flink源码阅读笔记"></a>Flink源码阅读笔记</h1><h2 id="WordCount程序总览"><a href="#WordCount程序总览" class="headerlink" title="WordCount程序总览"></a>WordCount程序总览</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">val env = StreamExecutionEnvironment.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">val text = env.addSource(new RandomLocalJsonSourceFunction(1,1000))</span><br><span class="line"></span><br><span class="line">val words = text.flatMap &#123; _.toLowerCase.split(&quot;\\W+&quot;) filter &#123; _.nonEmpty &#125; &#125;</span><br><span class="line">val counts = words</span><br><span class="line">  .map &#123; (_, 1) &#125;</span><br><span class="line">  .keyBy(0)</span><br><span class="line">  .sum(1)</span><br><span class="line"></span><br><span class="line">counts.print()</span><br><span class="line"></span><br><span class="line">env.execute(&quot;Window Stream WordCount&quot;)</span><br></pre></td></tr></table></figure>
<p>可以看到一个WordCount程序大概分为5个部分</p>
<ol>
<li>构建ExecutionEnvironment</li>
<li>添加Source</li>
<li>中间做各种Transformation</li>
<li>添加Sink</li>
<li>ExecutionEnvironment.execute方法</li>
</ol>
<h2 id="构建ExecutionEnvironment"><a href="#构建ExecutionEnvironment" class="headerlink" title="构建ExecutionEnvironment"></a>构建ExecutionEnvironment</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def getExecutionEnvironment: StreamExecutionEnvironment = &#123;</span><br><span class="line">  new StreamExecutionEnvironment(JavaEnv.getExecutionEnvironment)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>org.apache.flink.streaming.api.scala.StreamExecutionEnvironment和<strong>org.apache.flink.streaming.api.environment.StreamExecutionEnvironment</strong>需要区分对待。前者是对后者的封装，后者是核心类。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">public static StreamExecutionEnvironment getExecutionEnvironment() &#123;</span><br><span class="line">	if (contextEnvironmentFactory != null) &#123;</span><br><span class="line">		return contextEnvironmentFactory.createExecutionEnvironment();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	// because the streaming project depends on &quot;flink-clients&quot; (and not the other way around)</span><br><span class="line">	// we currently need to intercept the data set environment and create a dependent stream env.</span><br><span class="line">	// this should be fixed once we rework the project dependencies</span><br><span class="line"></span><br><span class="line">	ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">	if (env instanceof ContextEnvironment) &#123;</span><br><span class="line">		return new StreamContextEnvironment((ContextEnvironment) env);</span><br><span class="line">	&#125; else if (env instanceof OptimizerPlanEnvironment || env instanceof PreviewPlanEnvironment) &#123;</span><br><span class="line">		return new StreamPlanEnvironment(env);</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		return createLocalEnvironment();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>核心类StreamExecutionEnvironment.getExecutionEnvironment这个方法非常重要。核心类StreamExecutionEnvironment是抽象类，方法返回StreamExecutionEnvironment的具体子类。<br>在这个方法里实际做了两件事情：</p>
<ol>
<li>org.apache.flink.api.java.ExecutionEnvironment.getExecutionEnvironment返回org.apache.flink.api.java.LocalEnvironment。</li>
<li>然后调用createLocalEnvironment返回<strong>org.apache.flink.streaming.api.environment.LocalStreamEnvironment</strong>。<br>本地执行时，会将Runtime.getRuntime().availableProcessors()里面的值带到ExecutionConfig的parallelism属性里面。ExecutionConfig的parallelism会带到Transformation里面作为默认并行度</li>
</ol>
<h2 id="添加Source"><a href="#添加Source" class="headerlink" title="添加Source"></a>添加Source</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">  def addSource[T: TypeInformation](function: SourceFunction[T]): DataStream[T] = &#123;</span><br><span class="line">    require(function != null, &quot;Function must not be null.&quot;)</span><br><span class="line">    </span><br><span class="line">    val cleanFun = scalaClean(function)</span><br><span class="line">    val typeInfo = implicitly[TypeInformation[T]]</span><br><span class="line">    asScalaStream(javaEnv.addSource(cleanFun).returns(typeInfo))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">public &lt;OUT&gt; DataStreamSource&lt;OUT&gt; addSource(SourceFunction&lt;OUT&gt; function, String sourceName, TypeInformation&lt;OUT&gt; typeInfo) &#123;</span><br><span class="line"></span><br><span class="line">		if (typeInfo == null) &#123;</span><br><span class="line">			if (function instanceof ResultTypeQueryable) &#123;</span><br><span class="line">				typeInfo = ((ResultTypeQueryable&lt;OUT&gt;) function).getProducedType();</span><br><span class="line">			&#125; else &#123;</span><br><span class="line">				try &#123;</span><br><span class="line">					typeInfo = TypeExtractor.createTypeInfo(</span><br><span class="line">							SourceFunction.class,</span><br><span class="line">							function.getClass(), 0, null, null);</span><br><span class="line">				&#125; catch (final InvalidTypesException e) &#123;</span><br><span class="line">					typeInfo = (TypeInformation&lt;OUT&gt;) new MissingTypeInfo(sourceName, e);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		boolean isParallel = function instanceof ParallelSourceFunction;</span><br><span class="line"></span><br><span class="line">		clean(function);</span><br><span class="line">		StreamSource&lt;OUT, ?&gt; sourceOperator;</span><br><span class="line">		if (function instanceof StoppableFunction) &#123;</span><br><span class="line">			sourceOperator = new StoppableStreamSource&lt;&gt;(cast2StoppableSourceFunction(function));</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			sourceOperator = new StreamSource&lt;&gt;(function);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		return new DataStreamSource&lt;&gt;(this, typeInfo, sourceOperator, isParallel, sourceName);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>其中调用了LocalStreamEnvironment的addSource方法。返回一个DataStreamSource，这个是一个继承于DataStream的类。</p>
<p>先用StreamSource封装了function,然后用SourceTransformation封装了StreamSource，DataStreamSource封装了SourceTransformation。</p>
<h2 id="flatMap算子"><a href="#flatMap算子" class="headerlink" title="flatMap算子"></a>flatMap算子</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def flatMap[R: TypeInformation](fun: T =&gt; TraversableOnce[R]): DataStream[R] = &#123;</span><br><span class="line">  if (fun == null) &#123;</span><br><span class="line">    throw new NullPointerException(&quot;FlatMap function must not be null.&quot;)</span><br><span class="line">  &#125;</span><br><span class="line">  val cleanFun = clean(fun)</span><br><span class="line">  val flatMapper = new FlatMapFunction[T, R] &#123;</span><br><span class="line">    def flatMap(in: T, out: Collector[R]) &#123; cleanFun(in) foreach out.collect &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  flatMap(flatMapper)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在其中先用FlatMapFunction封装了自定义的函数（Function是最下面一级），然后调用了DataStream的flatMap重载<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public &lt;R&gt; SingleOutputStreamOperator&lt;R&gt; flatMap(FlatMapFunction&lt;T, R&gt; flatMapper) &#123;</span><br><span class="line"></span><br><span class="line">	TypeInformation&lt;R&gt; outType = TypeExtractor.getFlatMapReturnTypes(clean(flatMapper),</span><br><span class="line">			getType(), Utils.getCallLocationName(), true);</span><br><span class="line"></span><br><span class="line">	return transform(&quot;Flat Map&quot;, outType, new StreamFlatMap&lt;&gt;(clean(flatMapper)));</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>先用StreamFlatMap这个Operator封装了Function。然后在transform方法中，先用OneInputTransformation封装了StreamFlatMap，并设置input为之前的SourceTransformation。然后用SingleOutputStreamOperator封装了这个Transform</p>
<h2 id="map算子"><a href="#map算子" class="headerlink" title="map算子"></a>map算子</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def map[R: TypeInformation](fun: T =&gt; R): DataStream[R] = &#123;</span><br><span class="line">  if (fun == null) &#123;</span><br><span class="line">    throw new NullPointerException(&quot;Map function must not be null.&quot;)</span><br><span class="line">  &#125;</span><br><span class="line">  val cleanFun = clean(fun)</span><br><span class="line">  val mapper = new MapFunction[T, R] &#123;</span><br><span class="line">    def map(in: T): R = cleanFun(in)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  map(mapper)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>先用MapFunction封装了传入的function。然后调用了map的重载<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public &lt;R&gt; SingleOutputStreamOperator&lt;R&gt; map(MapFunction&lt;T, R&gt; mapper) &#123;</span><br><span class="line"></span><br><span class="line">	TypeInformation&lt;R&gt; outType = TypeExtractor.getMapReturnTypes(clean(mapper), getType(),</span><br><span class="line">			Utils.getCallLocationName(), true);</span><br><span class="line"></span><br><span class="line">	return transform(&quot;Map&quot;, outType, new StreamMap&lt;&gt;(clean(mapper)));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>先用StreamMap封装了Function。然后在transform方法中，先用OneInputTransformation封装了StreamFlatMap，并设置input为之前的SourceTransformation。然后用SingleOutputStreamOperator封装了这个Transform</p>
<h2 id="keyBy算子"><a href="#keyBy算子" class="headerlink" title="keyBy算子"></a>keyBy算子</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public KeyedStream&lt;T, Tuple&gt; keyBy(int... fields) &#123;</span><br><span class="line">	if (getType() instanceof BasicArrayTypeInfo || getType() instanceof PrimitiveArrayTypeInfo) &#123;</span><br><span class="line">		return keyBy(KeySelectorUtil.getSelectorForArray(fields, getType()));</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		return keyBy(new Keys.ExpressionKeys&lt;&gt;(fields, getType()));</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>先创建Keys.ExpressionKeys封装了总的类型和key字段类型，然后调用keyBy的重载<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">private KeyedStream&lt;T, Tuple&gt; keyBy(Keys&lt;T&gt; keys) &#123;</span><br><span class="line">	return new KeyedStream&lt;&gt;(this, clean(KeySelectorUtil.getSelectorForKeys(keys,</span><br><span class="line">			getType(), getExecutionConfig())));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>在这个重载方法中，先调用KeySelectorUtil.getSelectorForKeys生成了ComparableKeySelector，然后调用KeyedStream构造函数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public KeyedStream(DataStream&lt;T&gt; dataStream, KeySelector&lt;T, KEY&gt; keySelector, TypeInformation&lt;KEY&gt; keyType) &#123;</span><br><span class="line">	this(</span><br><span class="line">		dataStream,</span><br><span class="line">		new PartitionTransformation&lt;&gt;(</span><br><span class="line">			dataStream.getTransformation(),</span><br><span class="line">			new KeyGroupStreamPartitioner&lt;&gt;(keySelector, StreamGraphGenerator.DEFAULT_LOWER_BOUND_MAX_PARALLELISM)),</span><br><span class="line">		keySelector,</span><br><span class="line">		keyType);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>生成KeyGroupStreamPartitioner(类似于Operator)封装了ComparableKeySelector，然后PartitionTransformation封装了KeyGroupStreamPartitioner，然后KeyedStream封装了PartitionTransformation。<br><img src="15519530262226.jpg" alt=""><br>KeyGroupStreamPartitioner的两个泛型来自于构造函数的第一个参数keySelector。KeyGroupStreamPartitioner&lt;T, K&gt; extends StreamPartitioner<t><br>StreamPartitioner<t> implements<br>        ChannelSelector&lt;SerializationDelegate&lt;StreamRecord<t>&gt;&gt;</t></t></t></p>
<h2 id="sum算子"><a href="#sum算子" class="headerlink" title="sum算子"></a>sum算子</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">private def aggregate(aggregationType: AggregationType, position: Int): DataStream[T] = &#123;</span><br><span class="line"></span><br><span class="line">  val reducer = aggregationType match &#123;</span><br><span class="line">    case AggregationType.SUM =&gt;</span><br><span class="line">      new SumAggregator(position, javaStream.getType, javaStream.getExecutionConfig)</span><br><span class="line">    case _ =&gt;</span><br><span class="line">      new ComparableAggregator(position, javaStream.getType, aggregationType, true,</span><br><span class="line">        javaStream.getExecutionConfig)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  val invokable =  new StreamGroupedReduce[T](reducer,</span><br><span class="line">    getType().createSerializer(getExecutionConfig))</span><br><span class="line">   </span><br><span class="line">  new DataStream[T](javaStream.transform(&quot;aggregation&quot;, javaStream.getType(),invokable))</span><br><span class="line">    .asInstanceOf[DataStream[T]]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先生成SumAggregator(类似于Function)，然后生成StreamGroupedReduce(类似于Operator)封装了SumAggregator。然后在KeyedStream.transform方法中，先用OneInputTransformation封装了StreamGroupedReduce。然后用SingleOutputStreamOperator封装了这个Transform。然后设置了新生成的Transformation的stateKeySelector和stateKeyType属性。</p>
<h2 id="print算子"><a href="#print算子" class="headerlink" title="print算子"></a>print算子</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public DataStreamSink&lt;T&gt; print() &#123;</span><br><span class="line">	PrintSinkFunction&lt;T&gt; printFunction = new PrintSinkFunction&lt;&gt;();</span><br><span class="line">	return addSink(printFunction).name(&quot;Print to Std. Out&quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先生成一个PrintSinkFunction<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">public DataStreamSink&lt;T&gt; addSink(SinkFunction&lt;T&gt; sinkFunction) &#123;</span><br><span class="line"></span><br><span class="line">	// read the output type of the input Transform to coax out errors about MissingTypeInfo</span><br><span class="line">	transformation.getOutputType();</span><br><span class="line"></span><br><span class="line">	// configure the type if needed</span><br><span class="line">	if (sinkFunction instanceof InputTypeConfigurable) &#123;</span><br><span class="line">		((InputTypeConfigurable) sinkFunction).setInputType(getType(), getExecutionConfig());</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	StreamSink&lt;T&gt; sinkOperator = new StreamSink&lt;&gt;(clean(sinkFunction));</span><br><span class="line"></span><br><span class="line">	DataStreamSink&lt;T&gt; sink = new DataStreamSink&lt;&gt;(this, sinkOperator);</span><br><span class="line"></span><br><span class="line">	getExecutionEnvironment().addOperator(sink.getTransformation());</span><br><span class="line">	return sink;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>然后生成StreamSink封装了PrintSinkFunction，再生成SinkTransformation封装StreamSink，最后外面套一层DataStreamSink作为返回。</p>
<p>最终形成的图如下所示：<br><img src="15465706985211.jpg" alt=""><br>StreamExecutionEnvironment.transformations中有4个transformation，分别是OneInputTransformation,OneInputTransformation,OneInputTransformation,SinkTransformation。<br><strong>Stream之间的区别在于，KeyedStream多了keySelector和keyType属性。</strong><br><strong>每个transformation都要指定maxParallelism, minResources, preferredResources, bufferTimeout, name, outputType、parallelism和slotSharingGroup。</strong><br><strong>每个Operator上面定义了chainingStrategy, combinedWatermark, input1Watermark, input2Watermark,其中StreamGroupedReduce中还有serializer属性。</strong><br>Function如果是RichFunction，会有StreamingRuntimeContext传入（包含Operator,RuntimeEnvironment），会有open方法<br>Operator在initializeState时，创建了StreamTaskStateInitializerImpl</p>
<h2 id="StreamExecutionEnvironment-execute"><a href="#StreamExecutionEnvironment-execute" class="headerlink" title="StreamExecutionEnvironment.execute"></a>StreamExecutionEnvironment.execute</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">public JobExecutionResult execute(String jobName) throws Exception &#123;</span><br><span class="line">		// transform the streaming program into a JobGraph</span><br><span class="line">		StreamGraph streamGraph = getStreamGraph();</span><br><span class="line">		streamGraph.setJobName(jobName);</span><br><span class="line"></span><br><span class="line">		JobGraph jobGraph = streamGraph.getJobGraph();</span><br><span class="line">		jobGraph.setAllowQueuedScheduling(true);</span><br><span class="line"></span><br><span class="line">		Configuration configuration = new Configuration();</span><br><span class="line">		configuration.addAll(jobGraph.getJobConfiguration());</span><br><span class="line">		configuration.setString(TaskManagerOptions.MANAGED_MEMORY_SIZE, &quot;0&quot;);</span><br><span class="line"></span><br><span class="line">		// add (and override) the settings with what the user defined</span><br><span class="line">		configuration.addAll(this.configuration);</span><br><span class="line"></span><br><span class="line">		if (!configuration.contains(RestOptions.PORT)) &#123;</span><br><span class="line">			configuration.setInteger(RestOptions.PORT, 0);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		int numSlotsPerTaskManager = configuration.getInteger(TaskManagerOptions.NUM_TASK_SLOTS, jobGraph.getMaximumParallelism());</span><br><span class="line"></span><br><span class="line">		MiniClusterConfiguration cfg = new MiniClusterConfiguration.Builder()</span><br><span class="line">			.setConfiguration(configuration)</span><br><span class="line">			.setNumSlotsPerTaskManager(numSlotsPerTaskManager)</span><br><span class="line">			.build();</span><br><span class="line"></span><br><span class="line">		if (LOG.isInfoEnabled()) &#123;</span><br><span class="line">			LOG.info(&quot;Running job on local embedded Flink mini cluster&quot;);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		MiniCluster miniCluster = new MiniCluster(cfg);</span><br><span class="line"></span><br><span class="line">		try &#123;</span><br><span class="line">			miniCluster.start();</span><br><span class="line">			configuration.setInteger(RestOptions.PORT, miniCluster.getRestAddress().getPort());</span><br><span class="line"></span><br><span class="line">			return miniCluster.executeJobBlocking(jobGraph);</span><br><span class="line">		&#125;</span><br><span class="line">		finally &#123;</span><br><span class="line">			transformations.clear();</span><br><span class="line">			miniCluster.close();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>这一步骤比较长，分开来看：</p>
<h3 id="StreamExecutionEnvironment-getStreamGraph"><a href="#StreamExecutionEnvironment-getStreamGraph" class="headerlink" title="StreamExecutionEnvironment.getStreamGraph"></a>StreamExecutionEnvironment.getStreamGraph</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">@Internal</span><br><span class="line">public StreamGraph getStreamGraph() &#123;</span><br><span class="line">	if (transformations.size() &lt;= 0) &#123;</span><br><span class="line">		throw new IllegalStateException(&quot;No operators defined in streaming topology. Cannot execute.&quot;);</span><br><span class="line">	&#125;</span><br><span class="line">	return StreamGraphGenerator.generate(this, transformations);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>转发给StreamGraphGenerator.generate<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public static StreamGraph generate(StreamExecutionEnvironment env, List&lt;StreamTransformation&lt;?&gt;&gt; transformations) &#123;</span><br><span class="line">	return new StreamGraphGenerator(env).generateInternal(transformations);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>先实例化一个StreamGraphGenerator，然后调用generateInternal。StreamGraphGenerator实例化时实例化StreamGraph，将Environment本身、Environment的executionConfig、Environment的checkpointConfig、Environment的chaining、Environment的stateBackend带到StreamGraph中。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">private StreamGraph generateInternal(List&lt;StreamTransformation&lt;?&gt;&gt; transformations) &#123;</span><br><span class="line">	for (StreamTransformation&lt;?&gt; transformation: transformations) &#123;</span><br><span class="line">		transform(transformation);</span><br><span class="line">	&#125;</span><br><span class="line">	return streamGraph;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>在generateInternal方法中，对于每个transformation，调用transform<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">private Collection&lt;Integer&gt; transform(StreamTransformation&lt;?&gt; transform) &#123;</span><br><span class="line"></span><br><span class="line">		if (alreadyTransformed.containsKey(transform)) &#123;</span><br><span class="line">			return alreadyTransformed.get(transform);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		LOG.debug(&quot;Transforming &quot; + transform);</span><br><span class="line"></span><br><span class="line">		if (transform.getMaxParallelism() &lt;= 0) &#123;</span><br><span class="line"></span><br><span class="line">			// if the max parallelism hasn&apos;t been set, then first use the job wide max parallelism</span><br><span class="line">			// from theExecutionConfig.</span><br><span class="line">			int globalMaxParallelismFromConfig = env.getConfig().getMaxParallelism();</span><br><span class="line">			if (globalMaxParallelismFromConfig &gt; 0) &#123;</span><br><span class="line">				transform.setMaxParallelism(globalMaxParallelismFromConfig);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		// call at least once to trigger exceptions about MissingTypeInfo</span><br><span class="line">		transform.getOutputType();</span><br><span class="line"></span><br><span class="line">		Collection&lt;Integer&gt; transformedIds;</span><br><span class="line">		if (transform instanceof OneInputTransformation&lt;?, ?&gt;) &#123;</span><br><span class="line">			transformedIds = transformOneInputTransform((OneInputTransformation&lt;?, ?&gt;) transform);</span><br><span class="line">		&#125; else if (transform instanceof TwoInputTransformation&lt;?, ?, ?&gt;) &#123;</span><br><span class="line">			transformedIds = transformTwoInputTransform((TwoInputTransformation&lt;?, ?, ?&gt;) transform);</span><br><span class="line">		&#125; else if (transform instanceof SourceTransformation&lt;?&gt;) &#123;</span><br><span class="line">			transformedIds = transformSource((SourceTransformation&lt;?&gt;) transform);</span><br><span class="line">		&#125; else if (transform instanceof SinkTransformation&lt;?&gt;) &#123;</span><br><span class="line">			transformedIds = transformSink((SinkTransformation&lt;?&gt;) transform);</span><br><span class="line">		&#125; else if (transform instanceof UnionTransformation&lt;?&gt;) &#123;</span><br><span class="line">			transformedIds = transformUnion((UnionTransformation&lt;?&gt;) transform);</span><br><span class="line">		&#125; else if (transform instanceof SplitTransformation&lt;?&gt;) &#123;</span><br><span class="line">			transformedIds = transformSplit((SplitTransformation&lt;?&gt;) transform);</span><br><span class="line">		&#125; else if (transform instanceof SelectTransformation&lt;?&gt;) &#123;</span><br><span class="line">			transformedIds = transformSelect((SelectTransformation&lt;?&gt;) transform);</span><br><span class="line">		&#125; else if (transform instanceof FeedbackTransformation&lt;?&gt;) &#123;</span><br><span class="line">			transformedIds = transformFeedback((FeedbackTransformation&lt;?&gt;) transform);</span><br><span class="line">		&#125; else if (transform instanceof CoFeedbackTransformation&lt;?&gt;) &#123;</span><br><span class="line">			transformedIds = transformCoFeedback((CoFeedbackTransformation&lt;?&gt;) transform);</span><br><span class="line">		&#125; else if (transform instanceof PartitionTransformation&lt;?&gt;) &#123;</span><br><span class="line">			transformedIds = transformPartition((PartitionTransformation&lt;?&gt;) transform);</span><br><span class="line">		&#125; else if (transform instanceof SideOutputTransformation&lt;?&gt;) &#123;</span><br><span class="line">			transformedIds = transformSideOutput((SideOutputTransformation&lt;?&gt;) transform);</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			throw new IllegalStateException(&quot;Unknown transformation: &quot; + transform);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		// need this check because the iterate transformation adds itself before</span><br><span class="line">		// transforming the feedback edges</span><br><span class="line">		if (!alreadyTransformed.containsKey(transform)) &#123;</span><br><span class="line">			alreadyTransformed.put(transform, transformedIds);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		if (transform.getBufferTimeout() &gt;= 0) &#123;</span><br><span class="line">			streamGraph.setBufferTimeout(transform.getId(), transform.getBufferTimeout());</span><br><span class="line">		&#125;</span><br><span class="line">		if (transform.getUid() != null) &#123;</span><br><span class="line">			streamGraph.setTransformationUID(transform.getId(), transform.getUid());</span><br><span class="line">		&#125;</span><br><span class="line">		if (transform.getUserProvidedNodeHash() != null) &#123;</span><br><span class="line">			streamGraph.setTransformationUserHash(transform.getId(), transform.getUserProvidedNodeHash());</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		if (transform.getMinResources() != null &amp;&amp; transform.getPreferredResources() != null) &#123;</span><br><span class="line">			streamGraph.setResources(transform.getId(), transform.getMinResources(), transform.getPreferredResources());</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		return transformedIds;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure></p>
<table>
<thead>
<tr>
<th>StreamGraph</th>
<th>来源</th>
</tr>
</thead>
<tbody>
<tr>
<td>environment</td>
<td>environment</td>
</tr>
<tr>
<td>executionConfig</td>
<td>environment.ExecutionConfig</td>
</tr>
<tr>
<td>checkpointConfig</td>
<td>environment.CheckpointConfig</td>
</tr>
<tr>
<td>chaining</td>
<td>environment.isChainingEnabled</td>
</tr>
<tr>
<td>stateBackend</td>
<td>defaultStateBackend</td>
</tr>
<tr>
<td>jobName</td>
<td>外面带入</td>
</tr>
</tbody>
</table>
<p>对于每种不同的transformation，调用不同的逻辑。但基本原则都是在StreamGraph中生成对应的StreamNode。</p>
<table>
<thead>
<tr>
<th>Transformation</th>
<th>StreamNode</th>
</tr>
</thead>
<tbody>
<tr>
<td>id</td>
<td>id</td>
</tr>
<tr>
<td>name</td>
<td>operatorName</td>
</tr>
<tr>
<td>operator</td>
<td>operator</td>
</tr>
<tr>
<td></td>
<td>outputSelectors</td>
</tr>
<tr>
<td>根据不同的Transformation而不同</td>
<td>jobVertexClass</td>
</tr>
<tr>
<td>slotSharingGroup</td>
<td>slotSharingGroup</td>
</tr>
<tr>
<td>coLocationGroupKey</td>
<td>coLocationGroup</td>
</tr>
<tr>
<td>input.getOutputType()</td>
<td>typeSerializerIn1</td>
</tr>
<tr>
<td>outputType</td>
<td>typeSerializerOut</td>
</tr>
<tr>
<td>parallelism</td>
<td>parallelism</td>
</tr>
<tr>
<td>maxParallelism</td>
<td>maxParallelism</td>
</tr>
<tr>
<td>bufferTimeout</td>
<td>bufferTimeout</td>
</tr>
<tr>
<td>uid</td>
<td>transformationUID</td>
</tr>
<tr>
<td>userProvidedNodeHash</td>
<td>userHash</td>
</tr>
<tr>
<td>minResources</td>
<td>minResources</td>
</tr>
<tr>
<td>preferredResources</td>
<td>preferredResources</td>
</tr>
<tr>
<td>如果Transformation的stateKeySelector有</td>
<td>stateKeySerializer</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>类型</th>
<th>行为</th>
</tr>
</thead>
<tbody>
<tr>
<td>SourceTransformation</td>
<td>①streamGraph.addOperator</td>
</tr>
<tr>
<td>OneInputTransformation</td>
<td>①transform(input)  ②streamGraph.addOperator ③考虑设置statePartitioner1,stateKeySerializer ④streamGraph.addEdge，在这个节点的input和它本身之间建立边</td>
</tr>
<tr>
<td>PartitionTransformation</td>
<td>①transform(input) ②对每个input新建一个虚拟ID并调用streamGraph.addVirtualPartitionNode</td>
</tr>
<tr>
<td>SinkTransformation</td>
<td>①transform(input) ②streamGraph.addOperator ③考虑设置statePartitioner1,stateKeySerializer ④streamGraph.addEdge，在这个节点的input和它本身之间建立边</td>
</tr>
</tbody>
</table>
<p>以下详解主要方法：<br>streamGraph.addOperator(transformId, slotSharingGroup, coLocationGroupKey, operator, inType, outType, name)：7个参数传进来，取transformId, slotSharingGroup, coLocationGroupKey, operator, name再加1个vertexClass调用了addNode，然后根据inType和outType设置了StreamNode的serializer。</p>
<p>streamGraph.addNode(transformId, slotSharingGroup, coLocationGroup, operatorObject, operatorName, vertexClass)：对传入的参数增加一个Environment和outputSelector新建了StreamNode(transformId, slotSharingGroup, coLocationGroup, operatorObject,operatorName, vertexClass, outputSelector, env)</p>
<p>streamGraph.addEdge(upStreamVertexID,downStreamVertexID,typeNumber) ：主要是调用了addEdgeInternal。<br>addEdgeInternal：对于一般的input节点来说，先确认Partitioner，然后再创建StreamEdge(sourceVertex, targetVertex, typeNumber, outputPartitioner)，最终把StreamEdge加入到两端的StreamNode中。<br>对于input节点是虚拟节点的情况，重新计算背后指向的真正节点，并递归调用addEdgeInternal<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">	private void addEdgeInternal(Integer upStreamVertexID,</span><br><span class="line">			Integer downStreamVertexID,</span><br><span class="line">			int typeNumber,</span><br><span class="line">			StreamPartitioner&lt;?&gt; partitioner,</span><br><span class="line">			List&lt;String&gt; outputNames,</span><br><span class="line">			OutputTag outputTag) &#123;</span><br><span class="line"></span><br><span class="line">		if (virtualSideOutputNodes.containsKey(upStreamVertexID)) &#123;</span><br><span class="line">			int virtualId = upStreamVertexID;</span><br><span class="line">			upStreamVertexID = virtualSideOutputNodes.get(virtualId).f0;</span><br><span class="line">			if (outputTag == null) &#123;</span><br><span class="line">				outputTag = virtualSideOutputNodes.get(virtualId).f1;</span><br><span class="line">			&#125;</span><br><span class="line">			addEdgeInternal(upStreamVertexID, downStreamVertexID, typeNumber, partitioner, null, outputTag);</span><br><span class="line">		&#125; else if (virtualSelectNodes.containsKey(upStreamVertexID)) &#123;</span><br><span class="line">			int virtualId = upStreamVertexID;</span><br><span class="line">			upStreamVertexID = virtualSelectNodes.get(virtualId).f0;</span><br><span class="line">			if (outputNames.isEmpty()) &#123;</span><br><span class="line">				// selections that happen downstream override earlier selections</span><br><span class="line">				outputNames = virtualSelectNodes.get(virtualId).f1;</span><br><span class="line">			&#125;</span><br><span class="line">			addEdgeInternal(upStreamVertexID, downStreamVertexID, typeNumber, partitioner, outputNames, outputTag);</span><br><span class="line">		&#125; else if (virtualPartitionNodes.containsKey(upStreamVertexID)) &#123;</span><br><span class="line">			int virtualId = upStreamVertexID;</span><br><span class="line">			upStreamVertexID = virtualPartitionNodes.get(virtualId).f0;</span><br><span class="line">			if (partitioner == null) &#123;</span><br><span class="line">				partitioner = virtualPartitionNodes.get(virtualId).f1;</span><br><span class="line">			&#125;</span><br><span class="line">			addEdgeInternal(upStreamVertexID, downStreamVertexID, typeNumber, partitioner, outputNames, outputTag);</span><br><span class="line">		&#125; else &#123;</span><br><span class="line">			StreamNode upstreamNode = getStreamNode(upStreamVertexID);</span><br><span class="line">			StreamNode downstreamNode = getStreamNode(downStreamVertexID);</span><br><span class="line"></span><br><span class="line">			// If no partitioner was specified and the parallelism of upstream and downstream</span><br><span class="line">			// operator matches use forward partitioning, use rebalance otherwise.</span><br><span class="line">			if (partitioner == null &amp;&amp; upstreamNode.getParallelism() == downstreamNode.getParallelism()) &#123;</span><br><span class="line">				partitioner = new ForwardPartitioner&lt;Object&gt;();</span><br><span class="line">			&#125; else if (partitioner == null) &#123;</span><br><span class="line">				partitioner = new RebalancePartitioner&lt;Object&gt;();</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			if (partitioner instanceof ForwardPartitioner) &#123;</span><br><span class="line">				if (upstreamNode.getParallelism() != downstreamNode.getParallelism()) &#123;</span><br><span class="line">					throw new UnsupportedOperationException(&quot;Forward partitioning does not allow &quot; +</span><br><span class="line">							&quot;change of parallelism. Upstream operation: &quot; + upstreamNode + &quot; parallelism: &quot; + upstreamNode.getParallelism() +</span><br><span class="line">							&quot;, downstream operation: &quot; + downstreamNode + &quot; parallelism: &quot; + downstreamNode.getParallelism() +</span><br><span class="line">							&quot; You must use another partitioning strategy, such as broadcast, rebalance, shuffle or global.&quot;);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			StreamEdge edge = new StreamEdge(upstreamNode, downstreamNode, typeNumber, outputNames, partitioner, outputTag);</span><br><span class="line"></span><br><span class="line">			getStreamNode(edge.getSourceId()).addOutEdge(edge);</span><br><span class="line">			getStreamNode(edge.getTargetId()).addInEdge(edge);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">最终生成的StreamGraph如下图所示，总之在这一步：由StreamExecutionEnvironment的局部Transformation出发，由Transformation节点生成StreamNode，但有些Transformation没有进入StreamGraph；确定了边，边决定了数据路由到下游的方式。</span><br><span class="line">![-w941](15466760243164.jpg)</span><br><span class="line"></span><br><span class="line">### 由StreamGraph生成JobGraph</span><br></pre></td></tr></table></figure></p>
<p>private JobGraph createJobGraph() {</p>
<pre><code>    // make sure that all vertices start immediately
    jobGraph.setScheduleMode(ScheduleMode.EAGER);

    // Generate deterministic hashes for the nodes in order to identify them across
    // submission iff they didn&apos;t change.
    Map&lt;Integer, byte[]&gt; hashes = defaultStreamGraphHasher.traverseStreamGraphAndGenerateHashes(streamGraph);

    // Generate legacy version hashes for backwards compatibility
    List&lt;Map&lt;Integer, byte[]&gt;&gt; legacyHashes = new ArrayList&lt;&gt;(legacyStreamGraphHashers.size());
    for (StreamGraphHasher hasher : legacyStreamGraphHashers) {
        legacyHashes.add(hasher.traverseStreamGraphAndGenerateHashes(streamGraph));
    }

    Map&lt;Integer, List&lt;Tuple2&lt;byte[], byte[]&gt;&gt;&gt; chainedOperatorHashes = new HashMap&lt;&gt;();

    setChaining(hashes, legacyHashes, chainedOperatorHashes);

    setPhysicalEdges();

    setSlotSharingAndCoLocation();

    configureCheckpointing();

    JobGraphGenerator.addUserArtifactEntries(streamGraph.getEnvironment().getCachedFiles(), jobGraph);

    // set the ExecutionConfig last when it has been finalized
    try {
        jobGraph.setExecutionConfig(streamGraph.getExecutionConfig());
    }
    catch (IOException e) {
        throw new IllegalConfigurationException(&quot;Could not serialize the ExecutionConfig.&quot; +
                &quot;This indicates that non-serializable types (like custom serializers) were registered&quot;);
    }

    return jobGraph;
}
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">先生成StreamingJobGraphGenerator，然后再调用其createJobGraph方法。在StreamingJobGraphGenerator中实例化了JobGraph，设置了jobID( new JobID() )和jobName。接着在createJobGraph中，首先defaultStreamGraphHasher.traverseStreamGraphAndGenerateHashes(streamGraph);为每个StreamGraph节点生成Hash码。接着调用setChaining </span><br><span class="line"></span><br><span class="line">#### 调用setChaining</span><br></pre></td></tr></table></figure>
<pre><code>private void setChaining(Map&lt;Integer, byte[]&gt; hashes, List&lt;Map&lt;Integer, byte[]&gt;&gt; legacyHashes, Map&lt;Integer, List&lt;Tuple2&lt;byte[], byte[]&gt;&gt;&gt; chainedOperatorHashes) {
    for (Integer sourceNodeId : streamGraph.getSourceIDs()) {
        createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0, chainedOperatorHashes);
    }
}
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在setChaining中，从每个source出发，调用createChain</span><br></pre></td></tr></table></figure>
<p>private List<streamedge> createChain(<br>            Integer startNodeId,<br>            Integer currentNodeId,<br>            Map&lt;Integer, byte[]&gt; hashes,<br>            List&lt;Map&lt;Integer, byte[]&gt;&gt; legacyHashes,<br>            int chainIndex,<br>            Map&lt;Integer, List&lt;Tuple2&lt;byte[], byte[]&gt;&gt;&gt; chainedOperatorHashes) {</streamedge></p>
<pre><code>if (!builtVertices.contains(startNodeId)) {

    List&lt;StreamEdge&gt; transitiveOutEdges = new ArrayList&lt;StreamEdge&gt;();

    List&lt;StreamEdge&gt; chainableOutputs = new ArrayList&lt;StreamEdge&gt;();
    List&lt;StreamEdge&gt; nonChainableOutputs = new ArrayList&lt;StreamEdge&gt;();

    for (StreamEdge outEdge : streamGraph.getStreamNode(currentNodeId).getOutEdges()) {
        if (isChainable(outEdge, streamGraph)) {
            chainableOutputs.add(outEdge);
        } else {
            nonChainableOutputs.add(outEdge);
        }
    }

    for (StreamEdge chainable : chainableOutputs) {
        transitiveOutEdges.addAll(
                createChain(startNodeId, chainable.getTargetId(), hashes, legacyHashes, chainIndex + 1, chainedOperatorHashes));
    }

    for (StreamEdge nonChainable : nonChainableOutputs) {
        transitiveOutEdges.add(nonChainable);
        createChain(nonChainable.getTargetId(), nonChainable.getTargetId(), hashes, legacyHashes, 0, chainedOperatorHashes);
    }
</code></pre><p>//执行顺序，整体上来看，是以节点为树的深度优先遍历（函数有源参数和目的参数，中间可能会切源，目的参数随着遍历到的节点走）<br>//每一个源和它后面的所有能连上的节点在子节点执行完之后都会执行下面这段代码<br>//假设没有断边，那么就是一个标准的深度优先遍历</p>
<pre><code>List&lt;Tuple2&lt;byte[], byte[]&gt;&gt; operatorHashes =
    chainedOperatorHashes.computeIfAbsent(startNodeId, k -&gt; new ArrayList&lt;&gt;());

byte[] primaryHashBytes = hashes.get(currentNodeId);

for (Map&lt;Integer, byte[]&gt; legacyHash : legacyHashes) {
    operatorHashes.add(new Tuple2&lt;&gt;(primaryHashBytes, legacyHash.get(currentNodeId)));
}


chainedNames.put(currentNodeId, createChainedName(currentNodeId, chainableOutputs));
chainedMinResources.put(currentNodeId, createChainedMinResources(currentNodeId, chainableOutputs));
chainedPreferredResources.put(currentNodeId, createChainedPreferredResources(currentNodeId, chainableOutputs));

StreamConfig config = currentNodeId.equals(startNodeId)
        ? createJobVertex(startNodeId, hashes, legacyHashes, chainedOperatorHashes)
        : new StreamConfig(new Configuration());

setVertexConfig(currentNodeId, config, chainableOutputs, nonChainableOutputs);

if (currentNodeId.equals(startNodeId)) {
</code></pre><p>//设置config属性<br>                config.setChainStart();<br>                config.setChainIndex(0);<br>                config.setOperatorName(streamGraph.getStreamNode(currentNodeId).getOperatorName());<br>                config.setOutEdgesInOrder(transitiveOutEdges);<br>                config.setOutEdges(streamGraph.getStreamNode(currentNodeId).getOutEdges());</p>
<pre><code>            for (StreamEdge edge : transitiveOutEdges) {
                connect(startNodeId, edge);
            }

            config.setTransitiveChainedTaskConfigs(chainedConfigs.get(startNodeId));

        } else {
            Map&lt;Integer, StreamConfig&gt; chainedConfs = chainedConfigs.get(startNodeId);

            if (chainedConfs == null) {
                chainedConfigs.put(startNodeId, new HashMap&lt;Integer, StreamConfig&gt;());
            }
            config.setChainIndex(chainIndex);
            StreamNode node = streamGraph.getStreamNode(currentNodeId);
            config.setOperatorName(node.getOperatorName());
            chainedConfigs.get(startNodeId).put(currentNodeId, config);
        }

        config.setOperatorID(new OperatorID(primaryHashBytes));

        if (chainableOutputs.isEmpty()) {
            config.setChainEnd();
        }
        return transitiveOutEdges;

    } else {
        return new ArrayList&lt;&gt;();
    }
}
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">| JobGraph | 来源 | </span><br><span class="line">| --- | --- | </span><br><span class="line">| jobId | new JobID() |</span><br><span class="line">| jobName | StreamGraph.jobName |</span><br><span class="line">| serializedExecutionConfig | StreamGraph.executionConfig |</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">首先创建JobVertex，对应的属性和来源分别为：</span><br><span class="line"></span><br><span class="line">| JobVertex | 来源 | </span><br><span class="line">| --- | --- | </span><br><span class="line">| name | StreamNode.operatorName串 |</span><br><span class="line">| id | JobVertexID(hash) |</span><br><span class="line">| idAlternatives(没用) |  |</span><br><span class="line">| operatorIDs | OperatorID(hash)集合 |</span><br><span class="line">| operatorIdsAlternatives(没用) |  |</span><br><span class="line">| minResources | StreamNode.minResources串 |</span><br><span class="line">| preferredResources | StreamNode.preferredResources 串 |</span><br><span class="line">| invokableClassName | StreamNode.jobVertexClass|</span><br><span class="line">| isStoppable | StreamNode.jobVertexClass |</span><br><span class="line">| parallelism | StreamNode.parallelism |</span><br><span class="line">| maxParallelism | StreamNode.maxParallelism |</span><br><span class="line">| results | IDS集合 |</span><br><span class="line">| inputs | JobEdge集合 |</span><br><span class="line"></span><br><span class="line">接着创建StreamConfig，其值和来源分别为：</span><br><span class="line"></span><br><span class="line">| StreamConfig | 来源 | </span><br><span class="line">| --- | --- | </span><br><span class="line">| setVertexID | StreamNode.id |</span><br><span class="line">| setBufferTimeout | StreamNode.bufferTimeout |</span><br><span class="line">| setTypeSerializerIn1 | StreamNode.typeSerializerIn1 |</span><br><span class="line">| setTypeSerializerIn2 | StreamNode.typeSerializerIn2 |</span><br><span class="line">| setTypeSerializerOut | StreamNode.typeSerializerOut |</span><br><span class="line">| setStreamOperator | StreamNode.operator |</span><br><span class="line">| setOutputSelectors | StreamNode.outputSelectors |</span><br><span class="line">| setNumberOfOutputs | 每个StreamNode的outEdges为断的数量 |</span><br><span class="line">| setNonChainedOutputs | 每个StreamNode的outEdges为断的 |</span><br><span class="line">| setChainedOutputs | 每个StreamNode的outEdges为非断的 |</span><br><span class="line">| setTimeCharacteristic | StreamGraph.Environment.timeCharacteristic |</span><br><span class="line">| setStateBackend | StreamGraph.stateBackend |</span><br><span class="line">| setStatePartitioner | StreamNode.statePartitioner1 |</span><br><span class="line">| setStatePartitioner | StreamNode.statePartitioner2 |</span><br><span class="line">| setStateKeySerializer | StreamNode.stateKeySerializer |</span><br><span class="line">| setChainIndex | 在链上的位置，从0开始 |</span><br><span class="line">| setOperatorName | StreamNode.operatorName |</span><br><span class="line">| setOutEdgesInOrder | 传递断边集合StreamEdge |</span><br><span class="line">| setOutEdges | StreamNode的所有出边 |</span><br><span class="line">| setTransitiveChainedTaskConfigs | 链上的StreamConfig,不包括源 |</span><br><span class="line">| setOperatorID | OperatorID(hash) |</span><br><span class="line">| setNumberOfInputs | JobGraph中的输入数 |</span><br><span class="line">| setInPhysicalEdges |  |</span><br><span class="line"></span><br><span class="line">connect方法：</span><br><span class="line">physicalEdgesInOrder-把断边添加进去</span><br><span class="line">调用JobVertex.connectNewDataSetAsInput</span><br></pre></td></tr></table></figure>
<p>jobEdge = downStreamVertex.connectNewDataSetAsInput(<br>                    headVertex,<br>                    DistributionPattern.ALL_TO_ALL,<br>                    ResultPartitionType.PIPELINED_BOUNDED);<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">downStreamVertex.connectNewDataSetAsInput创建jobEdge</span><br></pre></td></tr></table></figure></p>
<pre><code>public JobEdge connectNewDataSetAsInput(
        JobVertex input,
        DistributionPattern distPattern,
        ResultPartitionType partitionType) {

    IntermediateDataSet dataSet = input.createAndAddResultDataSet(partitionType);

    JobEdge edge = new JobEdge(dataSet, this, distPattern);
    this.inputs.add(edge);
    dataSet.addConsumer(edge);
    return edge;
}
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">![](15468309151085.jpg)</span><br><span class="line"></span><br><span class="line">#### setPhysicalEdges</span><br><span class="line">为对应节点（JobVertex）的StreamConfig设置inStreamEdges， List[StreamEdge]</span><br><span class="line"></span><br><span class="line">#### setSlotSharingAndCoLocation</span><br><span class="line">为JobVertex设置setSlotSharingGroup</span><br><span class="line"></span><br><span class="line">#### 设置Checkpoint</span><br></pre></td></tr></table></figure>
<p>JobCheckpointingSettings settings = new JobCheckpointingSettings(<br>            triggerVertices,<br>            ackVertices,<br>            commitVertices,<br>            new CheckpointCoordinatorConfiguration(<br>                interval,<br>                cfg.getCheckpointTimeout(),<br>                cfg.getMinPauseBetweenCheckpoints(),<br>                cfg.getMaxConcurrentCheckpoints(),<br>                retentionAfterTermination,<br>                isExactlyOnce),<br>            serializedStateBackend,<br>            serializedHooks);<br><code>`</code></p>
<p>总之，JobGraph在StreamGraph的基础上，形成了这样的数据结构：<br><img src="15510811705376.jpg" alt="-w1000"><br>每个JobVertex的configuration中有属性指向对应StreamNode的出边。<br>每个JobVertex的configuration中有属性指向从它出发的传递断边。<br>每个JobVertex的configuration中有属性指向链上的StreamConfig集合，每个StreamConfig指向对应StreamNode的出边。<br>每个JobVertex的configuration中有属性指向它的入边</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/16/flink-component-communication/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="徐涛">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="徐涛的个人主页">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/02/16/flink-component-communication/" itemprop="url">Flink模块间通信图</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-02-16T17:12:58+08:00">
                2019-02-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Flink源码阅读笔记–集群启动篇"><a href="#Flink源码阅读笔记–集群启动篇" class="headerlink" title="Flink源码阅读笔记–集群启动篇"></a>Flink源码阅读笔记–集群启动篇</h1><h2 id="构建MiniCluster"><a href="#构建MiniCluster" class="headerlink" title="构建MiniCluster"></a>构建MiniCluster</h2><p>上一篇中分析到LocalStreamEnvironment的execute方法中生成JobGraph的过程。本篇接着分析剩下部分。</p>
<h2 id="MiniCluster-start"><a href="#MiniCluster-start" class="headerlink" title="MiniCluster.start"></a>MiniCluster.start</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br></pre></td><td class="code"><pre><span class="line">public void start() throws Exception &#123;</span><br><span class="line">		synchronized (lock) &#123;</span><br><span class="line">			checkState(!running, &quot;FlinkMiniCluster is already running&quot;);</span><br><span class="line"></span><br><span class="line">			LOG.info(&quot;Starting Flink Mini Cluster&quot;);</span><br><span class="line">			LOG.debug(&quot;Using configuration &#123;&#125;&quot;, miniClusterConfiguration);</span><br><span class="line"></span><br><span class="line">			final Configuration configuration = miniClusterConfiguration.getConfiguration();</span><br><span class="line">			final Time rpcTimeout = miniClusterConfiguration.getRpcTimeout();</span><br><span class="line">			final int numTaskManagers = miniClusterConfiguration.getNumTaskManagers();</span><br><span class="line">			final boolean useSingleRpcService = miniClusterConfiguration.getRpcServiceSharing() == RpcServiceSharing.SHARED;</span><br><span class="line"></span><br><span class="line">			try &#123;</span><br><span class="line">				initializeIOFormatClasses(configuration);</span><br><span class="line"></span><br><span class="line">				LOG.info(&quot;Starting Metrics Registry&quot;);</span><br><span class="line">				metricRegistry = createMetricRegistry(configuration);</span><br><span class="line">				this.jobManagerMetricGroup = MetricUtils.instantiateJobManagerMetricGroup(</span><br><span class="line">					metricRegistry,</span><br><span class="line">					&quot;localhost&quot;,</span><br><span class="line">					ConfigurationUtils.getSystemResourceMetricsProbingInterval(configuration));</span><br><span class="line"></span><br><span class="line">				final RpcService jobManagerRpcService;</span><br><span class="line">				final RpcService resourceManagerRpcService;</span><br><span class="line">				final RpcService[] taskManagerRpcServices = new RpcService[numTaskManagers];</span><br><span class="line"></span><br><span class="line">				// bring up all the RPC services</span><br><span class="line">				LOG.info(&quot;Starting RPC Service(s)&quot;);</span><br><span class="line"></span><br><span class="line">				// we always need the &apos;commonRpcService&apos; for auxiliary calls</span><br><span class="line">				commonRpcService = createRpcService(configuration, rpcTimeout, false, null);</span><br><span class="line"></span><br><span class="line">				// TODO: Temporary hack until the metric query service is ported to the RpcEndpoint</span><br><span class="line">				metricQueryServiceActorSystem = MetricUtils.startMetricsActorSystem(</span><br><span class="line">					configuration,</span><br><span class="line">					commonRpcService.getAddress(),</span><br><span class="line">					LOG);</span><br><span class="line">				metricRegistry.startQueryService(metricQueryServiceActorSystem, null);</span><br><span class="line"></span><br><span class="line">				if (useSingleRpcService) &#123;</span><br><span class="line">					for (int i = 0; i &lt; numTaskManagers; i++) &#123;</span><br><span class="line">						taskManagerRpcServices[i] = commonRpcService;</span><br><span class="line">					&#125;</span><br><span class="line"></span><br><span class="line">					jobManagerRpcService = commonRpcService;</span><br><span class="line">					resourceManagerRpcService = commonRpcService;</span><br><span class="line"></span><br><span class="line">					this.resourceManagerRpcService = null;</span><br><span class="line">					this.jobManagerRpcService = null;</span><br><span class="line">					this.taskManagerRpcServices = null;</span><br><span class="line">				&#125;</span><br><span class="line">				else &#123;</span><br><span class="line">					// start a new service per component, possibly with custom bind addresses</span><br><span class="line">					final String jobManagerBindAddress = miniClusterConfiguration.getJobManagerBindAddress();</span><br><span class="line">					final String taskManagerBindAddress = miniClusterConfiguration.getTaskManagerBindAddress();</span><br><span class="line">					final String resourceManagerBindAddress = miniClusterConfiguration.getResourceManagerBindAddress();</span><br><span class="line"></span><br><span class="line">					jobManagerRpcService = createRpcService(configuration, rpcTimeout, true, jobManagerBindAddress);</span><br><span class="line">					resourceManagerRpcService = createRpcService(configuration, rpcTimeout, true, resourceManagerBindAddress);</span><br><span class="line"></span><br><span class="line">					for (int i = 0; i &lt; numTaskManagers; i++) &#123;</span><br><span class="line">						taskManagerRpcServices[i] = createRpcService(</span><br><span class="line">								configuration, rpcTimeout, true, taskManagerBindAddress);</span><br><span class="line">					&#125;</span><br><span class="line"></span><br><span class="line">					this.jobManagerRpcService = jobManagerRpcService;</span><br><span class="line">					this.taskManagerRpcServices = taskManagerRpcServices;</span><br><span class="line">					this.resourceManagerRpcService = resourceManagerRpcService;</span><br><span class="line">				&#125;</span><br><span class="line"></span><br><span class="line">				// create the high-availability services</span><br><span class="line">				LOG.info(&quot;Starting high-availability services&quot;);</span><br><span class="line">				haServices = HighAvailabilityServicesUtils.createAvailableOrEmbeddedServices(</span><br><span class="line">					configuration,</span><br><span class="line">					commonRpcService.getExecutor());</span><br><span class="line"></span><br><span class="line">				blobServer = new BlobServer(configuration, haServices.createBlobStore());</span><br><span class="line">				blobServer.start();</span><br><span class="line"></span><br><span class="line">				heartbeatServices = HeartbeatServices.fromConfiguration(configuration);</span><br><span class="line"></span><br><span class="line">				// bring up the ResourceManager(s)</span><br><span class="line">				LOG.info(&quot;Starting ResourceManger&quot;);</span><br><span class="line">				resourceManagerRunner = startResourceManager(</span><br><span class="line">					configuration,</span><br><span class="line">					haServices,</span><br><span class="line">					heartbeatServices,</span><br><span class="line">					metricRegistry,</span><br><span class="line">					resourceManagerRpcService,</span><br><span class="line">					new ClusterInformation(&quot;localhost&quot;, blobServer.getPort()),</span><br><span class="line">					jobManagerMetricGroup);</span><br><span class="line"></span><br><span class="line">				blobCacheService = new BlobCacheService(</span><br><span class="line">					configuration, haServices.createBlobStore(), new InetSocketAddress(InetAddress.getLocalHost(), blobServer.getPort())</span><br><span class="line">				);</span><br><span class="line"></span><br><span class="line">				// bring up the TaskManager(s) for the mini cluster</span><br><span class="line">				LOG.info(&quot;Starting &#123;&#125; TaskManger(s)&quot;, numTaskManagers);</span><br><span class="line">				taskManagers = startTaskManagers(</span><br><span class="line">					configuration,</span><br><span class="line">					haServices,</span><br><span class="line">					heartbeatServices,</span><br><span class="line">					metricRegistry,</span><br><span class="line">					blobCacheService,</span><br><span class="line">					numTaskManagers,</span><br><span class="line">					taskManagerRpcServices);</span><br><span class="line"></span><br><span class="line">				// starting the dispatcher rest endpoint</span><br><span class="line">				LOG.info(&quot;Starting dispatcher rest endpoint.&quot;);</span><br><span class="line"></span><br><span class="line">				dispatcherGatewayRetriever = new RpcGatewayRetriever&lt;&gt;(</span><br><span class="line">					jobManagerRpcService,</span><br><span class="line">					DispatcherGateway.class,</span><br><span class="line">					DispatcherId::fromUuid,</span><br><span class="line">					20,</span><br><span class="line">					Time.milliseconds(20L));</span><br><span class="line">				final RpcGatewayRetriever&lt;ResourceManagerId, ResourceManagerGateway&gt; resourceManagerGatewayRetriever = new RpcGatewayRetriever&lt;&gt;(</span><br><span class="line">					jobManagerRpcService,</span><br><span class="line">					ResourceManagerGateway.class,</span><br><span class="line">					ResourceManagerId::fromUuid,</span><br><span class="line">					20,</span><br><span class="line">					Time.milliseconds(20L));</span><br><span class="line"></span><br><span class="line">				this.dispatcherRestEndpoint = new DispatcherRestEndpoint(</span><br><span class="line">					RestServerEndpointConfiguration.fromConfiguration(configuration),</span><br><span class="line">					dispatcherGatewayRetriever,</span><br><span class="line">					configuration,</span><br><span class="line">					RestHandlerConfiguration.fromConfiguration(configuration),</span><br><span class="line">					resourceManagerGatewayRetriever,</span><br><span class="line">					blobServer.getTransientBlobService(),</span><br><span class="line">					WebMonitorEndpoint.createExecutorService(</span><br><span class="line">						configuration.getInteger(RestOptions.SERVER_NUM_THREADS, 1),</span><br><span class="line">						configuration.getInteger(RestOptions.SERVER_THREAD_PRIORITY),</span><br><span class="line">						&quot;DispatcherRestEndpoint&quot;),</span><br><span class="line">					new AkkaQueryServiceRetriever(</span><br><span class="line">						metricQueryServiceActorSystem,</span><br><span class="line">						Time.milliseconds(configuration.getLong(WebOptions.TIMEOUT))),</span><br><span class="line">					haServices.getWebMonitorLeaderElectionService(),</span><br><span class="line">					new ShutDownFatalErrorHandler());</span><br><span class="line"></span><br><span class="line">				dispatcherRestEndpoint.start();</span><br><span class="line"></span><br><span class="line">				restAddressURI = new URI(dispatcherRestEndpoint.getRestBaseUrl());</span><br><span class="line"></span><br><span class="line">				// bring up the dispatcher that launches JobManagers when jobs submitted</span><br><span class="line">				LOG.info(&quot;Starting job dispatcher(s) for JobManger&quot;);</span><br><span class="line"></span><br><span class="line">				final HistoryServerArchivist historyServerArchivist = HistoryServerArchivist.createHistoryServerArchivist(configuration, dispatcherRestEndpoint);</span><br><span class="line"></span><br><span class="line">				dispatcher = new StandaloneDispatcher(</span><br><span class="line">					jobManagerRpcService,</span><br><span class="line">					Dispatcher.DISPATCHER_NAME + UUID.randomUUID(),</span><br><span class="line">					configuration,</span><br><span class="line">					haServices,</span><br><span class="line">					resourceManagerRunner.getResourceManageGateway(),</span><br><span class="line">					blobServer,</span><br><span class="line">					heartbeatServices,</span><br><span class="line">					jobManagerMetricGroup,</span><br><span class="line">					metricRegistry.getMetricQueryServicePath(),</span><br><span class="line">					new MemoryArchivedExecutionGraphStore(),</span><br><span class="line">					Dispatcher.DefaultJobManagerRunnerFactory.INSTANCE,</span><br><span class="line">					new ShutDownFatalErrorHandler(),</span><br><span class="line">					dispatcherRestEndpoint.getRestBaseUrl(),</span><br><span class="line">					historyServerArchivist);</span><br><span class="line"></span><br><span class="line">				dispatcher.start();</span><br><span class="line"></span><br><span class="line">				resourceManagerLeaderRetriever = haServices.getResourceManagerLeaderRetriever();</span><br><span class="line">				dispatcherLeaderRetriever = haServices.getDispatcherLeaderRetriever();</span><br><span class="line"></span><br><span class="line">				resourceManagerLeaderRetriever.start(resourceManagerGatewayRetriever);</span><br><span class="line">				dispatcherLeaderRetriever.start(dispatcherGatewayRetriever);</span><br><span class="line">			&#125;</span><br><span class="line">			catch (Exception e) &#123;</span><br><span class="line">				// cleanup everything</span><br><span class="line">				try &#123;</span><br><span class="line">					close();</span><br><span class="line">				&#125; catch (Exception ee) &#123;</span><br><span class="line">					e.addSuppressed(ee);</span><br><span class="line">				&#125;</span><br><span class="line">				throw e;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			// create a new termination future</span><br><span class="line">			terminationFuture = new CompletableFuture&lt;&gt;();</span><br><span class="line"></span><br><span class="line">			// now officially mark this as running</span><br><span class="line">			running = true;</span><br><span class="line"></span><br><span class="line">			LOG.info(&quot;Flink Mini Cluster started successfully&quot;);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<h3 id="构建RPC-Service"><a href="#构建RPC-Service" class="headerlink" title="构建RPC Service"></a>构建RPC Service</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">commonRpcService = createRpcService(configuration, rpcTimeout, false, null);</span><br></pre></td></tr></table></figure>
<p>再进去看看细节<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">protected RpcService createRpcService(</span><br><span class="line">		Configuration configuration,</span><br><span class="line">		Time askTimeout,</span><br><span class="line">		boolean remoteEnabled,</span><br><span class="line">		String bindAddress) &#123;</span><br><span class="line"></span><br><span class="line">	final Config akkaConfig;</span><br><span class="line"></span><br><span class="line">	if (remoteEnabled) &#123;</span><br><span class="line">		akkaConfig = AkkaUtils.getAkkaConfig(configuration, bindAddress, 0);</span><br><span class="line">	&#125; else &#123;</span><br><span class="line">		akkaConfig = AkkaUtils.getAkkaConfig(configuration);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	final Config effectiveAkkaConfig = AkkaUtils.testDispatcherConfig().withFallback(akkaConfig);</span><br><span class="line"></span><br><span class="line">	final ActorSystem actorSystem = AkkaUtils.createActorSystem(effectiveAkkaConfig);</span><br><span class="line"></span><br><span class="line">	return new AkkaRpcService(actorSystem, askTimeout);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>先用AkkaConfig创建了ActorSystem,然后用AkkaRpcService封装了ActorSystem</p>
<h3 id="构建HaService"><a href="#构建HaService" class="headerlink" title="构建HaService"></a>构建HaService</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">haServices = HighAvailabilityServicesUtils.createAvailableOrEmbeddedServices(</span><br><span class="line">					configuration,</span><br><span class="line">					commonRpcService.getExecutor());</span><br></pre></td></tr></table></figure>
<p>实际构建了一个EmbeddedHaServices。</p>
<p>EmbeddedHaServices中有resourceManagerLeaderService，dispatcherLeaderService，jobManagerLeaderServices（都是EmbeddedLeaderService）。</p>
<p>每个EmbeddedLeaderService可以创建EmbeddedLeaderElectionService，通过EmbeddedLeaderElectionService.start将EmbeddedLeaderElectionService关联到一个具体实体；然后EmbeddedLeaderService可以给对应的EmbeddedLeaderElectionService发送GrantLeadershipCall指令。</p>
<p>每个EmbeddedLeaderService也可以创建EmbeddedLeaderRetrievalService，通过EmbeddedLeaderRetrievalService.start将EmbeddedLeaderRetrievalService关联到一个具体实体的内部类；然后EmbeddedLeaderService可以发送NotifyOfLeaderCall，最终调用到对应实体的内部类</p>
<h3 id="创建BlobServer（不重要）"><a href="#创建BlobServer（不重要）" class="headerlink" title="创建BlobServer（不重要）"></a>创建BlobServer（不重要）</h3><h3 id="构建HeartbeatServices"><a href="#构建HeartbeatServices" class="headerlink" title="构建HeartbeatServices"></a>构建HeartbeatServices</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">heartbeatServices = HeartbeatServices.fromConfiguration(configuration);</span><br></pre></td></tr></table></figure>
<p>通过HeartbeatServices.createHeartbeatManagerSender可以创建HeartbeatManagerSenderImpl（通常会传入一个内部类HeartbeatListener处理对方实体的心跳丢失情况）。</p>
<p>HeartbeatManagerSenderImpl包含若干个HeartbeatMonitor，通过monitorTarget方法可以增加HeartbeatMonitor(对方的RPC实体-&gt;匿名HeartbeatTarget-&gt;HeartbeatMonitor)。</p>
<p>HeartbeatManagerSenderImpl本身是一个定时线程，轮询每个HeartbeatMonitor.HeartbeatTarget.requestHeartbeat。</p>
<p>HeartbeatManagerSenderImpl还包含receiveHeartbeat，调用对应的HeartbeatMonitor.reportHeartbeat。HeartbeatMonitor可以将超时信息发送给HeartbeatListener。</p>
<p>通过HeartbeatServices.createHeartbeatManager可以创建HeartbeatManagerImpl（通常会传入一个内部类HeartbeatListener处理对方实体的心跳丢失情况）</p>
<p>HeartbeatManagerImpl包含若干个HeartbeatMonitor，通过monitorTarget方法可以增加HeartbeatMonitor(对方的RPC实体-&gt;匿名HeartbeatTarget-&gt;HeartbeatMonitor)。</p>
<p>HeartbeatManagerImpl.requestHeartbeat里面主要做两件事1.调用对应的HeartbeatMonitor.reportHeartbeat。HeartbeatMonitor可以将超时信息发送给HeartbeatListener 2.HeartbeatMonitor.HeartbeatTarget.receiveHeartbeat</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">// 例如在ResourceManager中收到TaskExecutor注册时，会调用monitorTarget</span><br><span class="line">			taskManagerHeartbeatManager.monitorTarget(taskExecutorResourceId, new HeartbeatTarget&lt;Void&gt;() &#123;</span><br><span class="line">	@Override</span><br><span class="line">	public void receiveHeartbeat(ResourceID resourceID, Void payload) &#123;</span><br><span class="line">		// the ResourceManager will always send heartbeat requests to the</span><br><span class="line">		// TaskManager</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	public void requestHeartbeat(ResourceID resourceID, Void payload) &#123;</span><br><span class="line">		taskExecutorGateway.heartbeatFromResourceManager(resourceID);</span><br><span class="line">	&#125;</span><br><span class="line">	&#125;);</span><br></pre></td></tr></table></figure>
<h3 id="启动ResourceManager"><a href="#启动ResourceManager" class="headerlink" title="启动ResourceManager"></a>启动ResourceManager</h3><p>先创建ResourceManagerRunner，再调用ResourceManagerRunner.start</p>
<p>ResourceManagerRunner的核心在于StandaloneResourceManager，主要是指向SlotManager和JobLeaderIdService</p>
<h3 id="启动BlobCacheService（不重要）"><a href="#启动BlobCacheService（不重要）" class="headerlink" title="启动BlobCacheService（不重要）"></a>启动BlobCacheService（不重要）</h3><h3 id="启动TaskManager"><a href="#启动TaskManager" class="headerlink" title="启动TaskManager"></a>启动TaskManager</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">protected TaskExecutor[] startTaskManagers(</span><br><span class="line">			Configuration configuration,</span><br><span class="line">			HighAvailabilityServices haServices,</span><br><span class="line">			HeartbeatServices heartbeatServices,</span><br><span class="line">			MetricRegistry metricRegistry,</span><br><span class="line">			BlobCacheService blobCacheService,</span><br><span class="line">			int numTaskManagers,</span><br><span class="line">			RpcService[] taskManagerRpcServices) throws Exception &#123;</span><br><span class="line"></span><br><span class="line">		final TaskExecutor[] taskExecutors = new TaskExecutor[numTaskManagers];</span><br><span class="line">		final boolean localCommunication = numTaskManagers == 1;</span><br><span class="line"></span><br><span class="line">		for (int i = 0; i &lt; numTaskManagers; i++) &#123;</span><br><span class="line">			taskExecutors[i] = TaskManagerRunner.startTaskManager(</span><br><span class="line">				configuration,</span><br><span class="line">				new ResourceID(UUID.randomUUID().toString()),</span><br><span class="line">				taskManagerRpcServices[i],</span><br><span class="line">				haServices,</span><br><span class="line">				heartbeatServices,</span><br><span class="line">				metricRegistry,</span><br><span class="line">				blobCacheService,</span><br><span class="line">				localCommunication,</span><br><span class="line">				new TerminatingFatalErrorHandler(i));</span><br><span class="line"></span><br><span class="line">			taskExecutors[i].start();</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		return taskExecutors;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>先执行TaskManagerRunner.startTaskManager创建TaskExecutor（创建TaskExecutor时先构造TaskManagerServices），再执行TaskExecutor.start。</p>
<p>TaskManagerServices<br>—-&gt;NetworkEnvironment<br>——–&gt;NetworkBufferPool<br>——–&gt;LocalConnectionManager<br>——–&gt;ResultPartitionManager<br>——–&gt;TaskEventDispatcher<br>——–&gt;KvStateRegistry<br>—-&gt;MemoryManager(没什么用)<br>—-&gt;IOManager(Spill目录java.io.tmpdir/flink-io-UUID，一个读线程、一个写线程)<br>—-&gt;BroadcastVariableManager<br>—-&gt;TaskSlotTable(维护Slots)<br>—-&gt;JobManagerTable(维护JobId和JM关系的)<br>—-&gt;JobLeaderService(注意与JobLeaderIdService相区别，TM维护和JM连接的)<br>—-&gt;TaskExecutorLocalStateStoresManager(java.io.tmpdir/localState)      </p>
<hr>
<p>TaskExecutor.start会远程调用ResourceManager.registerTaskExecutor，此时将向ResourceManager汇报自己的节点情况和增加心跳相关信息；成功后将调用ResourceManager.sendSlotReport发送Slot报告并接收心跳信息。</p>
<p>ResourceManager.sendSlotReport<br>—-&gt;SlotManager.registerTaskManager<br>———&gt;注册TaskManagerRegistration<br>———&gt;SlotManager.registerSlot<br>————-&gt;创建TaskManagerSlot并加入</p>
<h3 id="启动StandaloneDispatcher"><a href="#启动StandaloneDispatcher" class="headerlink" title="启动StandaloneDispatcher"></a>启动StandaloneDispatcher</h3><p>StandaloneDispatcher包括的属性有几个比较特别，DefaultJobManagerRunnerFactory，StandaloneRunningJobsRegistry。<br>runningJobsRegistry<br>jobManagerRunnerFutures</p>
<h2 id="MiniCluster-executeJobBlocking"><a href="#MiniCluster-executeJobBlocking" class="headerlink" title="MiniCluster.executeJobBlocking"></a>MiniCluster.executeJobBlocking</h2><p>先调用StandaloneDispatcher.submitJob；再调用StandaloneDispatcher.requestJobResult。<br>注意这里Dispatcher是一个入口，它接受任务并完成它</p>
<h3 id="StandaloneDispatcher-submitJob"><a href="#StandaloneDispatcher-submitJob" class="headerlink" title="StandaloneDispatcher.submitJob"></a>StandaloneDispatcher.submitJob</h3><p>主要工作是创建JobManagerRunner并start它。实际是创建JobMaster并启动它。</p>
<ol>
<li>创建JobManagerRunner（本身没有什么），其中包含JobMaster<ul>
<li>会主动往TM发送心跳</li>
<li>同时接收RM的心跳</li>
<li>创建RestartStrategy</li>
<li>创建SlotPool</li>
<li>创建ExecutionGraph。关键是ExecutionGraph.attachJobGraph</li>
</ul>
</li>
<li>JobManagerRunner.start<br> 先往runningJobsRegistry注册； 最终调用到JobMaster.start</li>
</ol>
<h3 id="JobMaster-start"><a href="#JobMaster-start" class="headerlink" title="JobMaster.start"></a>JobMaster.start</h3><p>进入到JobMaster，在其中：</p>
<ol>
<li>启动相关服务<ul>
<li>SlotPool.start  </li>
<li>向ResourceManager发起注册<ul>
<li>调用ResourceManager.registerJobManager;</li>
<li>JobMaster.establishResourceManagerConnection</li>
</ul>
</li>
</ul>
</li>
<li>部署任务。核心是调用ExecutionGraph.scheduleForExecution<ul>
<li>Execution.allocateAndAssignSlotForExecution申请资源</li>
<li>对于每一个Execution调用其Execution.deploy</li>
</ul>
</li>
</ol>
<h4 id="Execution-allocateAndAssignSlotForExecution"><a href="#Execution-allocateAndAssignSlotForExecution" class="headerlink" title="Execution.allocateAndAssignSlotForExecution"></a>Execution.allocateAndAssignSlotForExecution</h4><ol>
<li><p>先计算preferredLocation<br>①节点本身Preferred的Locations只有ExecutionVertex.getPreferredLocations自己知道。而ExecutionVertex.getPreferredLocations内容是取自己上游的Execution的TaskManagerLocation集合作为PreferredLocations<br>②结合一个策略（默认是ALL，意味着ExecutionVertex.getPreferredLocations取出的候选都要确定，自己才继续申请slot）</p>
</li>
<li><p>SlotPool.allocateSlot，参数ScheduledUnit(Execution, SlotSharingGroupId)和SlotProfile(ResourceProfile, preferredLocations)</p>
</li>
<li>将LogicalSlot中的TaskManagerLocation信息设置到Execution中</li>
</ol>
<h4 id="Execution-deploy"><a href="#Execution-deploy" class="headerlink" title="Execution.deploy"></a>Execution.deploy</h4><ol>
<li><p>调用ExecutionVertex.createDeploymentDescriptor<br>每个ExecutionVertex可能会有多个IRP；也会有多个inputs。<br>（注意，现在的模式是一个consumer对应一个IRP）每个IRP生成一个ResultPartitionDeploymentDescriptor。<br>对于每一个上游生成一个InputGateDeploymentDescriptor，对于每一个上游里面的每个Partition生成一个InputChannelDeploymentDescriptor<br><img src="media/15468250974689/15620569452240.jpg" alt=""></p>
</li>
<li><p>TaskExecutor.submitTask</p>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">徐涛</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">徐涛</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
